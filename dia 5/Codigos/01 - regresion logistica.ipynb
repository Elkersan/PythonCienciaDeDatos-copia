{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Regresión Logística <a id=\"8\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Leer el Conjunto de Datos"]},{"cell_type":"markdown","metadata":{},"source":["El conjunto de datos incluye información sobre:\n","\n","* Clientes que se fueron en el último mes: la columna se llama `Churn`.\n","* Servicios a los que se ha suscrito cada cliente: teléfono, líneas múltiples, Internet, seguridad en línea, copia de seguridad en línea, protección de dispositivos, soporte técnico y transmisión de TV y películas.\n","* Información de la cuenta del cliente: cuánto tiempo ha sido cliente, contrato, método de pago, facturación electrónica, cargos mensuales y cargos totales.\n","* Información demográfica sobre clientes: género, rango de edad y si tienen pareja o personas dependientes.\n","\n","**ChurnData.csv** es un archivo de datos hipotéticos sobre los esfuerzos de una empresa de telecomunicaciones para reducir la rotación de su base de clientes. Cada caso corresponde a un cliente por separado y registra diversa información demográfica y de uso del servicio. "]},{"cell_type":"markdown","metadata":{},"source":["Cargar los datos y guardarlos en el dataframe `df4`:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ruta de datos y leer los datos\n","\n","path4='datos/ChurnData.csv'\n","df4 = pd.read_csv(path4)\n","df4.head()"]},{"cell_type":"markdown","metadata":{},"source":["Tamaño y forma del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Tamaño: ', df4.size)\n","print('Forma: ', df4.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-procesamiento de los Datos"]},{"cell_type":"markdown","metadata":{},"source":["Primero se seleccionarán algunas características para el modelado. También se procederá a cambiar el tipo de datos de destino para que sea un número entero, ya que es un requisito del módulo a utilizar de `scikit-learn`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df4_fuga = df4[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']].copy()\n","df4_fuga['churn'] = df4_fuga['churn'].astype(int)\n","df4_fuga.head()"]},{"cell_type":"markdown","metadata":{},"source":["Tamaño y forma del nuevo conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Tamaño: ', df4_fuga.size)\n","print('Forma: ', df4_fuga.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Definir **X4** e **y4** a partir del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4 = np.asarray(df4_fuga[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n","X4[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4 = np.asarray(df4_fuga['churn'])\n","y4 [0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Además, se procederá a normalizar el conjunto de datos asociado a la variable **X4**:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4 = preprocessing.StandardScaler().fit_transform(X4)\n","X4[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Configuración del Modelo"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, se procederá a dividir el conjunto de datos en el conjunto de entrenamiento y el conjunto de prueba en una proporción 80/20 respectivamente.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4_entrena, X4_prueba, y4_entrena, y4_prueba = train_test_split(X4, y4, test_size=0.2, random_state=4)\n","print ('Conjunto de Entrenamiento set:', X4_entrena.shape,  y4_entrena.shape)\n","print ('Conjunto de Prueba:', X4_prueba.shape,  y4_prueba.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelado"]},{"cell_type":"markdown","metadata":{},"source":["El siguiente paso es construir el modelo usando el módulo `LogisticRegression` del la biblioteca `Scikit-learn`. Esta función implementa la regresión logística y puede usar diferentes optimizadores numéricos para encontrar parámetros, incluidos los solucionadores `newton-cg`, `lbfgs`, `liblinear`, `sag`, `saga`. En una búsqueda en Internet se puede encontrar amplia información sobre los pros y los contras de estos optimizadores.\n","\n","La versión de `LogisticRegression` en `Scikit-learn` admite la regularización. La regularización es una técnica utilizada para resolver el problema de sobreajuste en los modelos de aprendizaje automático.\n","\n","El parámetro `C` indica la **fuerza de regularización inversa**, que debe ser un valor flotante positivo. Los valores más pequeños especifican una regularización más fuerte.\n","\n","Ahora se procederá a importar el módulo `LogisticRegression` y posteriormente se ajustará el modelo con el conjunto de entrenamiento."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","regr_logi = LogisticRegression(C=0.01, solver='liblinear').fit(X4_entrena,y4_entrena)\n","regr_logi"]},{"cell_type":"markdown","metadata":{},"source":["## Pronóstico"]},{"cell_type":"markdown","metadata":{},"source":["Una vez entrenado el modelo se puede realizar el pronóstico con el conjunto de datos de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4_hat = regr_logi.predict(X4_prueba)\n","y4_hat"]},{"cell_type":"markdown","metadata":{},"source":["La función `predict_proba` devuelve estimaciones para todas las clases, ordenadas por la etiqueta de las clases. Así, la primera columna es la probabilidad de la clase 0, $P(Y=0|X)$, y la segunda columna es la probabilidad de la clase 1, $P(Y=1|X)$:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4_hat_prob = regr_logi.predict_proba(X4_prueba)\n","y4_hat_prob"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{},"source":["**Índice de Jaccard**\n","\n","Se utilizará el **índice jaccard** para evaluar la precisión. Este índice se puede definir como el tamaño de la intersección dividido por el tamaño de la unión de dos conjuntos de etiquetas. Si todo el conjunto de etiquetas pronosticadas para una muestra coincide estrictamente con el verdadero conjunto de etiquetas, entonces la precisión del subconjunto es $1,0$; de lo contrario es $0,0$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics.jaccard_score(y4_prueba, y4_hat)"]},{"cell_type":"markdown","metadata":{},"source":["**Matiz de Confusión**\n","\n","Otra forma de ver la precisión del clasificador es utilizar la **matriz de confusión**. Esta es una herramienta útil para medir que tan bueno es un modelo clasificación. En particular, sirve para mostrar de forma explícita cuándo una clase es confundida con otra, lo cual, permite trabajar de forma separada con distintos tipos de error. Esta matriz se presenta siempre en forma de tabla, de manera que en cada columna aparece el número de predicciones de cada clase, mientras que cada fila muestra el número real de instancias de cada clase. Es decir, esta matriz pone en relación las predicciones realizadas por un modelo de clasificación y los resultados correctos que debería haber mostrado. Así puede medirse el desempeño del mismo, determinando qué tipo de errores y de aciertos tiene cada modelo.\n","\n","A continuación se define una función para graficar una matriz de confusión."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Esta función imprime y grafica una matriz de confusión.\n","# Se puede aplicar una normalización configurando el parámetro `normalize=True`.\n","\n","import itertools\n","\n","def grafica_matriz_confusion(matr_conf, clases,\n","                          normalizar=False,\n","                          titulo='Matriz de Confusión',\n","                          cmap=plt.cm.Blues):\n","\n","    if normalizar:\n","        matr_conf = matr_conf.astype('float') / matr_conf.sum(axis=1)[:, np.newaxis]\n","        print(\"Matriz de Confusión Normalizada.\")\n","    else:\n","        print('Matriz de Confusión matrix sin normalización')\n","\n","    print(matr_conf)\n","\n","    plt.imshow(matr_conf, interpolation='nearest', cmap=cmap)\n","    plt.title(titulo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(clases))\n","    plt.xticks(tick_marks, clases, rotation=45)\n","    plt.yticks(tick_marks, clases)\n","\n","    formato = '.2f' if normalizar else 'd'\n","    umbral = matr_conf.max() / 2.\n","    for i, j in itertools.product(range(matr_conf.shape[0]), range(matr_conf.shape[1])):\n","        plt.text(j, i, format(matr_conf[i, j], formato),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if matr_conf[i, j] > umbral else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Etiqueta valores Verdaderos')\n","    plt.xlabel('Etiqueta valores Pronosticados')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcular matriz de confusión\n","\n","matriz_confusion = metrics.confusion_matrix(y4_prueba, y4_hat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","# Grafica matriz de confusión no normalizada\n","plt.figure()\n","grafica_matriz_confusion(matriz_confusion, clases=['churn=1','churn=0'],normalizar= False,  titulo='Matriz de Confusión')"]},{"cell_type":"markdown","metadata":{},"source":["**Análisis de la primera fila**: La primera fila es para clientes cuyo valor real de abandono en el conjunto de prueba es 1 (es decir, abandona la compañía). Como se puede calcular, de 40 clientes, 15 de ellos tienen el valor de abandono en 1. Y de estos 15, el clasificador predijo correctamente 6 de ellos como 1 y predijo erróneamente 9 de ellos como 0.\n","\n","Esto significa que, para 6 clientes, el valor real de abandono fue 1 en el conjunto de prueba, y el clasificador también los predijo correctamente como 1. Sin embargo, mientras que la etiqueta real de 9 clientes fue 1, el clasificador los predijo como 0, lo cual no es correcto. Esto se puede considerar como un error del modelo para la primera fila.\n","\n","**Análisis de la segunda fila**: Hay 25 clientes cuyo valor de abandono era 0 (es decir, se queda en la compañía). El clasificador predijo correctamente 24 de ellos como 0 y uno de ellos incorrectamente como 1. Por lo tanto, ha hecho un buen trabajo al predecir los clientes con un valor de abandono de 0. \n","\n","Lo bueno de la matriz de confusión es que muestra la capacidad del modelo para predecir correctamente o separar las clases. En el caso específico del clasificador binario, como este ejemplo, podemos interpretar estos números como el recuento de verdaderos positivos (TP), falsos positivos (FP), verdaderos negativos (TN) y falsos negativos (FN)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (metrics.classification_report(y4_prueba, y4_hat))"]},{"cell_type":"markdown","metadata":{},"source":["Basado en el recuento de cada sección, se puede calcular la precisión y la sensibilidad de cada etiqueta:\n","\n","* **Precisión** es una medida de la exactitud siempre que se haya predicho una etiqueta de clase, es decir, se refiere a lo cerca que está el resultado de una predicción del valor verdadero. Se define por: $Precision = TP / (TP + FP)$.\n","\n","* **Sensibilidad** es la tasa positiva verdadera que representa la habilidad del modelo de detectar los casos relevantes. Se define como: $Recall = TP / (TP + FN)$.\n","\n","Así, ahora se puede calcular la precisión y la sensibilidad de cada clase.\n","\n","**Valor de F1:**\n","El siguiente paso es calcular los valores de F1 para cada etiqueta en función de la precisión y la sensibilidad de esa etiqueta.\n","\n","El valor de F1 es el promedio armónico de precisión y sensibilidad, donde un valor de F1 alcanza su mejor valor en 1 (precisión y sensibilidad perfectas) y el peor en 0. Es una buena manera de mostrar que un clasificador tiene un buen valor para ambos, sensibilidad y precisión.\n","\n","De esta manera, se puede decir que la precisión promedio de este clasificador es el promedio de la puntuación F1 para ambas etiquetas, el cual es 0,72 en este caso."]},{"cell_type":"markdown","metadata":{},"source":["**Pérdida Logística**\n","\n","La pérdida logística o **log-loss** es una métrica que indica qué tan cerca está la probabilidad de predicción del valor real/verdadero correspondiente (0 o 1 en caso de clasificación binaria). Cuanto más diverja la probabilidad predicha del valor real, mayor será el valor de pérdida logarítmica.\n","\n","Ahora, se probará realizar una evaluación  **log-loss** para el modelo. En la regresión logística, el resultado puede ser que la probabilidad de abandono de clientes sea sí (o igual a 1). Esta probabilidad es un valor entre 0 y 1. Por lo tanto, **log-loss** mide el rendimiento de un clasificador donde la salida prevista es un valor de probabilidad entre 0 y 1.\n","\n","Este indicador se utiliza, principalmente para comparar modelos. El modelo que tenga el menor valor de **log-loss** será el mejor evaluado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (\"Pérdila logística: %.4f\" % metrics.log_loss(y4_prueba, y4_hat_prob))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"95a1c2e80f057afcd5a481c3cc5cf533e1011abe1809e08fa3f649259a6254cc"}}},"nbformat":4,"nbformat_minor":2}
