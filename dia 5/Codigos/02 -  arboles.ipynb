{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 2. Árboles de Decisión <a id=\"6\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## Leer el Conjunto de Datos"]},{"cell_type":"markdown","metadata":{},"source":["Cargar los datos y guardarlos en el dataframe `df3`:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ruta de datos y leer los datos\n","\n","path3='datos/drug200.csv'\n","df3 = pd.read_csv(path3)\n","df3.head()"]},{"cell_type":"markdown","metadata":{},"source":["Tamaño y forma del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Tamaño: ', df3.size)\n","print('Forma: ', df3.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-procesamiento de los Datos"]},{"cell_type":"markdown","metadata":{},"source":["Usar el dataframe `df3`, leído con *Pandas*, con los datos del conjunto de datos `drug200.csv` para convertirlo y declarar las siguientes variables:\n","\n","* **X3** como la Matriz de características.\n","* **y3** como el Vector de respuesta u objetivo.\n","\n","Para la matriz de características se va a incorporar todas las columnas excepto la última que corresponde al vector de respuesta."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X3 = df3[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n","X3[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Se debe obserbar que algunas características en este conjunto de datos son categóricas, como `Sex` o `BP`. Desafortunadamente, el módulo de *Árboles de Decisión* de la biblioteca *Scikit-learn* no maneja variables categóricas. Sin embrago, es posible convertir estas características en valores numéricos utilizando el método de *Pandas* `pandas.get_dummies()`.\n","\n","De esta forma se procederá a convertir las variables categóricas en variables dummy/indicadoras."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["codificador_etiqueta_Sex = preprocessing.LabelEncoder()\n","codificador_etiqueta_Sex.fit(['F','M'])\n","X3[:,1] = codificador_etiqueta_Sex.transform(X3[:,1]) \n","\n","\n","codificador_etiqueta_BP = preprocessing.LabelEncoder()\n","codificador_etiqueta_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\n","X3[:,2] = codificador_etiqueta_BP.transform(X3[:,2])\n","\n","\n","codificador_etiqueta_Cholesterol = preprocessing.LabelEncoder()\n","codificador_etiqueta_Cholesterol.fit([ 'NORMAL', 'HIGH'])\n","X3[:,3] = codificador_etiqueta_Cholesterol.transform(X3[:,3]) \n","\n","X3[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Una vez arreglada la matriz de características **X** su puede proceder a crear el vector de destino **y**."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y3 = df3[\"Drug\"]\n","y3[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Configuración del Modelo"]},{"cell_type":"markdown","metadata":{},"source":["A continuación, se procederá a la configuración del Árbol de Decisiones. Para ello, se usará la división de los conjuntos de entrenamiento y de prueba para árbol de decisión. \n","\n","Para este caso en particular, se declararán los 4 parámetros de salida con los nombres: `X3_entrena`, `X3_prueba`, `y3_entrena` e `y3_prueba`.\n","\n","A la función `train_test_split` se le ingresarán los siguientes parámetros: `X3`, `y3`, `test_size=0.3` y `random_state=3`.\n","\n","Recordar que `X3` e `y3` son los arreglos requeridos para poder realizar la divsión, `test_size` representa la proporción del conjunto de datos de prueba y `random_state` asegura que obtengamos las mismas divisiones.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X3_entrena, X3_prueba, y3_entrena, y3_prueba = train_test_split(X3, y3, test_size=0.3, random_state=3)\n","print ('Conjunto de Entrenamiento set:', X3_entrena.shape,  y3_entrena.shape)\n","print ('Conjunto de Prueba:', X3_prueba.shape,  y3_prueba.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelado"]},{"cell_type":"markdown","metadata":{},"source":["Primero que nada, hay que importar y cargar el módulo `tree` que habilita el clasificador que implementa el modelo del Árbol de Decisiones."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{},"source":["A continuación, se procede a crear una instancia de `DecisionTreeClassifier` llamada `arbol_modelo`. Dentro del clasificador, se va a configurar el parámetro `criterion=\"entropy\"` para que se pueda observar ver la ganancia de información de cada nodo."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["arbol_modelo = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6)\n","arbol_modelo"]},{"cell_type":"markdown","metadata":{},"source":["A continuación, se procederá a ajustar el modelo con los conjuntos de datos de entrenamiento `X3_entrena` e `y3_entrena`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["arbol_modelo.fit(X3_entrena,y3_entrena)"]},{"cell_type":"markdown","metadata":{},"source":["## Pronóstico"]},{"cell_type":"markdown","metadata":{},"source":["Una vez entrenado el modelo se puede proceder a realizar algunas predicciones con el conjunto de datos de prueba, las cuales serán almacenadas en una variable llamada `arbol_pronostico`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["arbol_pronostico = arbol_modelo.predict(X3_prueba)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora se puede imprimir `arbol_pronostico` e `y3_prueba` para comparar visualmente la predicción con los valores reales."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (arbol_pronostico [0:5])\n","print (y3_prueba [0:5])"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{},"source":["A continuación, el siguiente paso consiste en utilizar las métricas de **sklearn** y verifiquemos la precisión del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Precición del modelo basado en árbol de decisiones: \", metrics.accuracy_score(y3_prueba, arbol_pronostico))"]},{"cell_type":"markdown","metadata":{},"source":["La **puntuación de la precisión del clasificador** calcula la precisión del subconjunto conformado por el conjunto de etiquetas pronosticado para una muestra dada, el cual debería coincidir exactamente con el conjunto de etiquetas correspondiente en **y_prueba** o **y_verdadrero** o **y_real**.\n","\n","En la clasificación multi-etiqueta, la función devuelve la precisión del subconjunto. Si todo el conjunto de etiquetas pronosticadas para una muestra coincide estrictamente con el verdadero conjunto de etiquetas, entonces la precisión del subconjunto es $1,0$; de lo contrario es $0,0$.\n","\n","Una forma de calcular la precisión del modelo sin usar **sklearn** sería de la siguiente forma."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["precision_alternativo = np.sum(np.equal(y3_prueba, arbol_pronostico)) / len(y3_prueba)\n","precision_alternativo"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"95a1c2e80f057afcd5a481c3cc5cf533e1011abe1809e08fa3f649259a6254cc"}}},"nbformat":4,"nbformat_minor":2}
