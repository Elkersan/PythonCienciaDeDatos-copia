{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 3. Máquinas de Vectores de Soporte <a id=\"10\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## Leer el Conjunto de Datos"]},{"cell_type":"markdown","metadata":{},"source":["Cargar los datos y guardarlos en el dataframe `df5`:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ruta de datos y leer los datos\n","\n","path5='datos/cell_samples.csv'\n","df5 = pd.read_csv(path5)\n","df5.head()"]},{"cell_type":"markdown","metadata":{},"source":["Tamaño y forma del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Tamaño: ', df5.size)\n","print('Forma: ', df5.shape)"]},{"cell_type":"markdown","metadata":{},"source":["El campo `ID` contiene los identificadores de los pacientes. Las características de las muestras de células de cada paciente están contenidas entre los campos `Clump` a `Mit`. Los valores se clasifican del 1 al 10, siendo 1 el más cercano a benigno.\n","\n","El campo Clase contiene el diagnóstico, confirmado por procedimientos médicos separados, en cuanto a si las muestras son benignas (valor = 2) o malignas (valor = 4).\n","\n","Por ejemplo, se puede observar la distribución de las clases según el grosor de los grumos y la uniformidad del tamaño de la celda para los 50 primeros registros."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ax = df5[df5['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='maligno');\n","df5[df5['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benigno', ax=ax);\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-procesamiento de los Datos"]},{"cell_type":"markdown","metadata":{},"source":["Lo primero es observar los tipos de datos de las columnas del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df5.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se puede ver que la columna `BareNuc` incluye algunos valores que no son numéricos. Por este motivo se va a proceder a eliminar esas filas. Para hacer esto se usará el método de *pandas* `.to_numeric` con el parámetro `error=coerce` para convertir los valores inválidos como `NaN`. A su vez, se le aplicará el método `.notnull()` para eliminar las filas que contengan un valor `NaN`. Se terminará esta etapa convirtiendo los valores al tipo entero."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df5 = df5[pd.to_numeric(df5['BareNuc'], errors='coerce').notnull()]\n","df5['BareNuc'] = df5['BareNuc'].astype('int')\n","df5.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["Con el atributo `shape` se puede observar que se eliminaron 16 filas, es decir se pasó de 699 filas a 683 filas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Forma: ', df5.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, ya está todo listo para definir **X5** e **y5** a partir del dataframe ya procesado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X5 = np.asarray(df5[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']])\n","X5[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Recordar que el objetivo es crear un modelo que prediga el valor de la clase, es decir, benigno (=2) o maligno (=4). "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y5 = np.asarray(df5['Class'])\n","y5 [0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Configuración del Modelo"]},{"cell_type":"markdown","metadata":{},"source":["El siguiente paso es dividir el conjunto de datos en el conjunto de entrenamiento y el conjunto de prueba"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X5_entrena, X5_prueba, y5_entrena, y5_prueba = train_test_split(X5, y5, test_size=0.2, random_state=4)\n","print ('Conjunto de Entrenamiento set:', X5_entrena.shape,  y5_entrena.shape)\n","print ('Conjunto de Prueba:', X5_prueba.shape,  y5_prueba.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelado"]},{"cell_type":"markdown","metadata":{},"source":["El algoritmo SVM ofrece una colección de funciones de **kernel** para realizar su procesamiento. Básicamente, el mapeo de datos en un espacio dimensional superior se llama **kernelling**. La función matemática utilizada para la transformación se conoce como **función kernel** y puede ser de diferentes tipos, como por ejemplo:\n","\n","1. Lineal.\n","2. Polinomial\n","3. Función de base radial (RBF).\n","4. Sigmoide.\n","\n","Cada una de estas funciones tiene sus características, sus pros y sus contras, sin embargo, no hay una manera fácil de saber qué función funcionará mejor con un conjunto de datos determinado. Generalmente, se eligen diferentes funciones a la vez y se comparan los resultados. En esta oportunidad se usará el kernel RBF (función de base radial) para el desarrollo de esta parte.\n","\n","Ahora se procederá a importar el módulo `svm` y posteriormente se ajustará el modelo con el conjunto de entrenamiento."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import svm\n","\n","modelo_svm = svm.SVC(kernel='rbf')\n","modelo_svm.fit(X5_entrena, y5_entrena) "]},{"cell_type":"markdown","metadata":{},"source":["## Pronóstico"]},{"cell_type":"markdown","metadata":{},"source":["Una vez entrenado el modelo se puede realizar el pronóstico con el conjunto de datos de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y5_hat = modelo_svm.predict(X5_prueba)\n","y5_hat"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{},"source":["Para el paso de evaluación se va a reutilizar la función `grafica_matrix_confusion` para observar la precisión del modelo generado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Esta función imprime y grafica una matriz de confusión.\n","# Se puede aplicar una normalización configurando el parámetro `normalize=True`.\n","\n","import itertools\n","\n","def grafica_matriz_confusion(matr_conf, clases,\n","                          normalizar=False,\n","                          titulo='Matriz de Confusión',\n","                          cmap=plt.cm.Blues):\n","\n","    if normalizar:\n","        matr_conf = matr_conf.astype('float') / matr_conf.sum(axis=1)[:, np.newaxis]\n","        print(\"Matriz de Confusión Normalizada.\")\n","    else:\n","        print('Matriz de Confusión matrix sin normalización')\n","\n","    print(matr_conf)\n","\n","    plt.imshow(matr_conf, interpolation='nearest', cmap=cmap)\n","    plt.title(titulo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(clases))\n","    plt.xticks(tick_marks, clases, rotation=45)\n","    plt.yticks(tick_marks, clases)\n","\n","    formato = '.2f' if normalizar else 'd'\n","    umbral = matr_conf.max() / 2.\n","    for i, j in itertools.product(range(matr_conf.shape[0]), range(matr_conf.shape[1])):\n","        plt.text(j, i, format(matr_conf[i, j], formato),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if matr_conf[i, j] > umbral else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Etiqueta valores Verdaderos')\n","    plt.xlabel('Etiqueta valores Pronosticados')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcular matriz de confusión\n","matriz_confusion = metrics.confusion_matrix(y5_prueba, y5_hat, labels=[2,4])\n","np.set_printoptions(precision=2)\n","\n","print (metrics.classification_report(y5_prueba, y5_hat))\n","\n","# Grafica matriz de confusión no normalizada\n","plt.figure()\n","grafica_matriz_confusion(matriz_confusion, clases=['Benigno(2)','Maligno(4)'],normalizar= False,  titulo='Matriz de Confusión')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["También se puede usar fácilmente el **Valor de F1** de la biblioteca `sklearn`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics.f1_score(y5_prueba, y5_hat, average='weighted') "]},{"cell_type":"markdown","metadata":{},"source":["Por otro lado, además se puede probar el **índice de Jaccard** para medir la precisión."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics.jaccard_score(y5_prueba, y5_hat, pos_label=2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"95a1c2e80f057afcd5a481c3cc5cf533e1011abe1809e08fa3f649259a6254cc"}}},"nbformat":4,"nbformat_minor":2}
